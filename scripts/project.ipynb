{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e6783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Poojitha Pasala\"\n",
    "EMAIL = \"poojithapasala@arizona.edu\"\n",
    "Topic = \"STAT-NLP Kaggle Class Competition 2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Steps for Reproducibility:\n",
    "\n",
    "### The process involved containerizing the model using Docker.\n",
    "### First, Docker was utilized to build the image, followed by launching the container to execute the code.\n",
    "### Below are the commands used:\n",
    "### docker build -t myimage\n",
    "### docker run -it -p 7777:9999 -v \"$PWD:/app/\" myimage:latest\n",
    "\n",
    "### Dependencies: Run below commands before running the below python cells.\n",
    "### pip install pandas\n",
    "### pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf4f0c",
   "metadata": {},
   "source": [
    "### Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abc6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import class_weight "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f777d2",
   "metadata": {},
   "source": [
    "### Pre-processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27aeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessor(text):\n",
    "    \"\"\"\n",
    "    Custom text preprocessing function that performs pattern substitutions using regular expressions.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input text to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    str: Preprocessed text after applying pattern substitutions.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define regular expressions for specific pattern substitutions\n",
    "    url_exp = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))'\n",
    "    url_exp2 = r'\\b(?:www\\.)[a-zA-Z0-9]+\\b'    \n",
    "    number_exp = r'\\b\\d{5}\\b'\n",
    "    currency_exp = r'Â£\\d+(,\\d+)*'\n",
    "    msg_exp = r'\\b(?:[a-zA-Z])*\\d+/\\w+\\b'\n",
    "    \n",
    "    # Perform pattern substitutions using regular expressions\n",
    "    text = text.lower()\n",
    "    text = re.sub(url_exp, '<URL>', text)\n",
    "    text = re.sub(url_exp2, '<URL1>', text)    \n",
    "    text = re.sub(number_exp, '<NUMBER1>', text)\n",
    "    text = re.sub(currency_exp, '<CURR>', text)\n",
    "    text = re.sub(msg_exp, '<MSG>', text)\n",
    "    \n",
    "    return text        \n",
    "\n",
    "# Load the train and test data\n",
    "train_df = pd.read_csv(\"/app/data/train.csv\")\n",
    "test_df = pd.read_csv(\"/app/data/test.csv\")\n",
    "\n",
    "# Handle missing values in the 'TEXT' column\n",
    "train_df['TEXT'] = train_df['TEXT'].fillna('')\n",
    "test_df['TEXT'] = test_df['TEXT'].fillna('')\n",
    "\n",
    "# Apply custom pre-processing to the text data\n",
    "train_df['TEXT'] = train_df['TEXT'].apply(custom_preprocessor)\n",
    "test_df['TEXT'] = test_df['TEXT'].apply(custom_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3677ca",
   "metadata": {},
   "source": [
    "## Feature Engineering with TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9141ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "\n",
    "# Transform training text data into TF-IDF features\n",
    "X_train = vectorizer.fit_transform(train_df['TEXT'])\n",
    "\n",
    "# Transform test text data into TF-IDF features\n",
    "X_test = vectorizer.transform(test_df['TEXT'])\n",
    "\n",
    "# Assign labels from training data to y_train\n",
    "y_train = train_df['LABEL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba51b4a1",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac1ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced dataset\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=pd.unique(y_train), y=y_train)\n",
    "\n",
    "# Train the logistic regression model with optimized hyperparameters\n",
    "model = LogisticRegression(max_iter=3000, class_weight=dict(zip(pd.unique(y_train), class_weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7a965",
   "metadata": {},
   "source": [
    "## Cross-Validation & Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bb0e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.9298178046830866\n",
      "Cross-Validation F1-score: 0.9294968814556201\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using cross-validation with accuracy scoring\n",
    "cv_accuracy = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Evaluate model using cross-validation with F1-score weighting\n",
    "cv_f1 = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "\n",
    "# Print mean cross-validation scores\n",
    "print(\"Cross-Validation Accuracy:\", cv_accuracy.mean())\n",
    "print(\"Cross-Validation F1-score:\", cv_f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6fb852",
   "metadata": {},
   "source": [
    "## Making Predictions and Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b0f84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the entire training set -Fit the logistic regression model on the entire training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the trained model\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Update the 'LABEL' column in the test DataFrame with the predicted labels\n",
    "test_df['LABEL'] = y_test_pred\n",
    "\n",
    "# Save predictions to a submission CSV file\n",
    "test_df[['ID', 'LABEL']].to_csv('submission.csv', index=False)\n",
    "\n",
    "# Print confirmation that test set predictions have been saved\n",
    "print('Test set predictions saved to submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
